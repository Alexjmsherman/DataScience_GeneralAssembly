{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# questions and personal notes\n",
    "#problems with reading this as $600 value for W/D - linear regression\n",
    "#('w/d hookups', -358.55112862600521), ('w/d in unit', 323.94738691104828),\n",
    "\n",
    "#Still need to remove (dummmy variable values that have only a few instances - e.g. only one person from city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from math import exp\n",
    "\n",
    "# allow plots to appear directly in the notebook\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\alsherman\\Desktop\\GitHub\\DataScience_GeneralAssembly\\Data\\Cleaned_Data_May_18.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>latitude</th>\n",
       "      <th>location_data_accuracy</th>\n",
       "      <th>longitude</th>\n",
       "      <th>average_image_size</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>bedroom</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>...</th>\n",
       "      <th>price</th>\n",
       "      <th>smoking</th>\n",
       "      <th>square_footage</th>\n",
       "      <th>grocery_list</th>\n",
       "      <th>gym_list</th>\n",
       "      <th>movie_theatre_list</th>\n",
       "      <th>subway_station_list</th>\n",
       "      <th>Barnes_and_Nobles_list</th>\n",
       "      <th>Deloitte_list</th>\n",
       "      <th>Starbucks_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0</td>\n",
       "      <td>5005421838</td>\n",
       "      <td>39.118608</td>\n",
       "      <td>0</td>\n",
       "      <td>-77.211356</td>\n",
       "      <td>270000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1750</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0</td>\n",
       "      <td>5005421838</td>\n",
       "      <td>39.118608</td>\n",
       "      <td>0</td>\n",
       "      <td>-77.211356</td>\n",
       "      <td>270000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1750</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0</td>\n",
       "      <td>5005421838</td>\n",
       "      <td>39.118608</td>\n",
       "      <td>0</td>\n",
       "      <td>-77.211356</td>\n",
       "      <td>270000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1750</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0</td>\n",
       "      <td>5005421838</td>\n",
       "      <td>39.118608</td>\n",
       "      <td>0</td>\n",
       "      <td>-77.211356</td>\n",
       "      <td>270000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1750</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0</td>\n",
       "      <td>5005421838</td>\n",
       "      <td>39.118608</td>\n",
       "      <td>0</td>\n",
       "      <td>-77.211356</td>\n",
       "      <td>270000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1750</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0</td>\n",
       "      <td>5005421838</td>\n",
       "      <td>39.118608</td>\n",
       "      <td>0</td>\n",
       "      <td>-77.211356</td>\n",
       "      <td>270000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1750</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0          ID   latitude  location_data_accuracy  longitude  \\\n",
       "count           1           1   1.000000                       1   1.000000   \n",
       "mean            0  5005421838  39.118608                       0 -77.211356   \n",
       "std           NaN         NaN        NaN                     NaN        NaN   \n",
       "min             0  5005421838  39.118608                       0 -77.211356   \n",
       "25%             0  5005421838  39.118608                       0 -77.211356   \n",
       "50%             0  5005421838  39.118608                       0 -77.211356   \n",
       "75%             0  5005421838  39.118608                       0 -77.211356   \n",
       "max             0  5005421838  39.118608                       0 -77.211356   \n",
       "\n",
       "       average_image_size  bathroom  bedroom  cat  dog       ...        price  \\\n",
       "count                   1       1.0        1    1    1       ...            1   \n",
       "mean               270000       2.5        3    0    0       ...         1750   \n",
       "std                   NaN       NaN      NaN  NaN  NaN       ...          NaN   \n",
       "min                270000       2.5        3    0    0       ...         1750   \n",
       "25%                270000       2.5        3    0    0       ...         1750   \n",
       "50%                270000       2.5        3    0    0       ...         1750   \n",
       "75%                270000       2.5        3    0    0       ...         1750   \n",
       "max                270000       2.5        3    0    0       ...         1750   \n",
       "\n",
       "       smoking  square_footage  grocery_list  gym_list  movie_theatre_list  \\\n",
       "count        1               0             1         1                   1   \n",
       "mean         0             NaN             0         0                   0   \n",
       "std        NaN             NaN           NaN       NaN                 NaN   \n",
       "min          0             NaN             0         0                   0   \n",
       "25%          0             NaN             0         0                   0   \n",
       "50%          0             NaN             0         0                   0   \n",
       "75%          0             NaN             0         0                   0   \n",
       "max          0             NaN             0         0                   0   \n",
       "\n",
       "       subway_station_list  Barnes_and_Nobles_list  Deloitte_list  \\\n",
       "count                    1                       1              1   \n",
       "mean                     0                       0              0   \n",
       "std                    NaN                     NaN            NaN   \n",
       "min                      0                       0              0   \n",
       "25%                      0                       0              0   \n",
       "50%                      0                       0              0   \n",
       "75%                      0                       0              0   \n",
       "max                      0                       0              0   \n",
       "\n",
       "       Starbucks_list  \n",
       "count               1  \n",
       "mean                0  \n",
       "std               NaN  \n",
       "min                 0  \n",
       "25%                 0  \n",
       "50%                 0  \n",
       "75%                 0  \n",
       "max                 0  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transform categorical fields to numeric for scikit-learn \n",
    "\n",
    "data.country = np.where(data.country == 'US',1,0)\n",
    "data.availability = np.where(data.availability == 'available now',1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>location_data_accuracy</th>\n",
       "      <th>longitude</th>\n",
       "      <th>state</th>\n",
       "      <th>availability</th>\n",
       "      <th>average_image_size</th>\n",
       "      <th>...</th>\n",
       "      <th>md</th>\n",
       "      <th>park</th>\n",
       "      <th>potomac</th>\n",
       "      <th>rainier</th>\n",
       "      <th>ridge</th>\n",
       "      <th>spring</th>\n",
       "      <th>springs</th>\n",
       "      <th>va</th>\n",
       "      <th>village</th>\n",
       "      <th>washington</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4959351766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>270000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          ID city  country  latitude  location_data_accuracy  \\\n",
       "0           0  4959351766  NaN        0         0                       0   \n",
       "\n",
       "   longitude state  availability  average_image_size    ...     md  park  \\\n",
       "0          0   NaN             1              270000    ...      0     0   \n",
       "\n",
       "   potomac rainier ridge  spring springs  va village washington  \n",
       "0        0       0     0       0       0   0       0          0  \n",
       "\n",
       "[1 rows x 171 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummy variables\n",
    "\n",
    "data = pd.concat([data, pd.get_dummies(data.housing_type)], axis=1)\n",
    "data = pd.concat([data, pd.get_dummies(data.laundry)], axis=1)\n",
    "data = pd.concat([data, pd.get_dummies(data.parking)], axis=1)\n",
    "data = pd.concat([data, pd.get_dummies(data.city)], axis=1)\n",
    "data = pd.concat([data, pd.get_dummies(data.state)], axis=1)\n",
    "\n",
    "data[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols = ['latitude',\t 'location_data_accuracy',\t 'longitude',\t 'average_image_size',\t 'bedroom',\t 'cat',\t 'dog',\t 'image_number',\t 'smoking',\t 'square_footage',\t 'grocery_list',\t 'gym_list',\t 'movie_theatre_list',\t 'train_station_list',\t 'airport_list',\t 'subway_station_list',\t 'Barnes_and_Nobles_list',\t 'Deloitte_list',\t 'Starbucks_list',\t 'No_Housing_Data',\t 'apartment',\t 'condo',\t 'cottage/cabin',\t 'duplex',\t 'flat',\t 'house',\t 'in-law',\t\t\n",
    " 'townhouse',\t 'No_Laundry_Data',\t 'laundry in bldg',\t 'laundry on site',\t 'w/d hookups',\t 'w/d in unit',\t 'No_Parking_Data',\t 'attached garage',\t 'carport',\t 'detached garage',\t 'off-street parking',\t 'street parking',\t 'aldie',\t 'alexandria',\t 'annandale',\t 'arlington',\t 'ashburn',\t 'baltimore',\t 'beltsville',\t 'bethesda',\t 'bladensburg',\t 'bowie',\t 'broadlands',\t 'capitol',\t 'centreville',\t 'chantilly',\t 'chevy',\t 'clinton',\t 'college',\n",
    " 'columbia',\t 'crofton',\t 'dale',\t 'damascus',\t 'dumfries',\t 'elkridge',\t 'fairfax',\t 'falls',\t 'forestville',\t 'frederick',\t 'fredericksburg',\t 'gaithersburg',\t 'germantown',\t 'greenbelt',\t 'hamilton',\t 'harpers',\t 'herndon',\t 'hyattsville',\t 'kensington',\t 'landover',\t 'largo',\t 'laurel',\t 'laytonsville',\t 'leesburg',\t 'lorton',\t 'manassas',\t 'mclean',\t 'montgomery',\t 'n',\n",
    " 'north',\t 'northwest',\t 'oak',\t 'oakton',\t 'oxon',\t 'potomac',\t 'reston',\t 'riverdale',\t 'rockville',\t 'rosslyn',\t 'silver',\t 'springfield',\t 'stafford',\t 'sterling',\t 'stone',\t 'suitland',\t 'takoma',\t 'triangle',\t 'upper',\t 'vienna',\t 'waldorf',\t 'washingtondc',\t 'wheaton',\t 'woodbridge',\t 'bethesda',\t 'chase',\t 'church',\t 'college',\t 'dc',\n",
    " 'falls',\t 'ferry',\t 'heights',\t 'hill',\t 'marlboro',\t 'park',\t 'potomac',\t 'ridge',\t 'spring',\t 'village',\t 'washington']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "#'city',\n",
    "#'country',\n",
    "'latitude',\n",
    "    #'location_data_accuracy',\n",
    "'longitude',\n",
    "\n",
    "#'state',\n",
    "#'availability',\n",
    "    #'average_image_size',\n",
    "'bathroom',\n",
    "'bedroom',\n",
    "    \n",
    "\n",
    "    #'cat',\n",
    "#'date_available',\n",
    "#'description',\n",
    "    #'dog',\n",
    "#'housing_type',\n",
    "'image_number',\n",
    "#'laundry',\n",
    "#'parking',\n",
    "    #'smoking',\n",
    "'square_footage',    \n",
    "\n",
    "#'url',\n",
    "'grocery_list',\n",
    "'gym_list',\n",
    "#'movie_theatre_list',\n",
    "#'train_station_list',\n",
    "#'airport_list',\n",
    "#'subway_station_list',\n",
    "#'Barnes_and_Nobles_list',\n",
    "#'Deloitte_list',\n",
    "#'Starbucks_list',\n",
    "    \n",
    "#'time_of_day_of_posting',\n",
    "#'date_of_posting',\n",
    "    #'No_Housing_Data',\n",
    "    #'apartment',\n",
    "    #'condo',\n",
    "    #'cottage/cabin',\n",
    "    #'duplex',\n",
    "    #'flat',\n",
    "    #'house',\n",
    "    #'in-law',\n",
    "    #'townhouse',\n",
    "    #'No_Laundry_Data',\n",
    "    #'laundry in bldg',\n",
    "    #'laundry on site',\n",
    "    #'w/d hookups',\n",
    "    #'w/d in unit',\n",
    "    #'No_Parking_Data'\n",
    "    \n",
    "'arlington',\n",
    "'dc',\n",
    "    \n",
    "'attached garage',\n",
    "    #'carport',\n",
    "    #'detached garage',\n",
    "'off-street parking',\n",
    "'street parking', \n",
    "    \n",
    "\n",
    "]\n",
    "\n",
    "set(data.park)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000973709834469\n"
     ]
    }
   ],
   "source": [
    "### SCIKIT-LEARN ###\n",
    "\n",
    "# create X and y\n",
    "X = data[feature_cols]\n",
    "y = data.price\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 2)\n",
    "\n",
    "# instantiate and fit\n",
    "lm2 = LinearRegression()\n",
    "lm2.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lm2.predict(X_test) # Predict\n",
    "# print the intercept\n",
    "#print lm2.intercept_\n",
    "\n",
    "# pair the feature names with the coefficients\n",
    "#print zip(feature_cols, lm2.coef_)\n",
    "\n",
    "# Access accuracy\n",
    "y_pred = [int(y) for y in y_pred]\n",
    "y_test = [int(y) for y in y_test]\n",
    "\n",
    "print metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.246348588121\n"
     ]
    }
   ],
   "source": [
    "# create X and y\n",
    "\n",
    "#feature_cols = []\n",
    "\n",
    "X = data[feature_cols]\n",
    "y = data.price\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 2)\n",
    "\n",
    "# Fit model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test) # Predict\n",
    "\n",
    "# Access accuracy\n",
    "print metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Create a Confusion Matrix\n",
    "\n",
    "con_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "print con_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import class, instantiate estimator, fit with all data\n",
    "rfclf = RandomForestClassifier(n_estimators=200, max_features=7, oob_score=True, random_state=1)\n",
    "rfclf.fit(X_train, y_train)\n",
    "\n",
    "# compute the out-of-bag classification accuracy\n",
    "rfclf.oob_score_\n",
    "\n",
    "print len(feature_cols)\n",
    "print len(rfclf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute the feature importances\n",
    "Feature_Importance = pd.DataFrame({'feature':feature_cols, 'importance':rfclf.feature_importances_})\n",
    "Feature_Importance.sort('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create Train Test split for text data (listing description)\n",
    "\n",
    "naive_bayes_feature_cols = 'description'\n",
    "\n",
    "# create X and y\n",
    "X = data[naive_bayes_feature_cols]\n",
    "y = data.price\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COUNTVECTORIZER: 'convert text into a matrix of token counts'\n",
    "# instantiate the vectorizer\n",
    "vect = CountVectorizer()\n",
    "\n",
    "# learn vocabulary and create document-term matrix in a single step\n",
    "train_dtm = vect.fit_transform(X_train)\n",
    "train_dtm\n",
    "\n",
    "# transform testing data into a document-term matrix\n",
    "test_dtm = vect.transform(X_test)\n",
    "test_dtm\n",
    "\n",
    "# store feature names and examine them\n",
    "train_features = vect.get_feature_names()\n",
    "len(train_features)\n",
    "train_features[:50]\n",
    "train_features[-50:]\n",
    "\n",
    "# convert train_dtm to a regular array\n",
    "train_arr = train_dtm.toarray()\n",
    "train_arr\n",
    "\n",
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(train_dtm.toarray(), columns=vect.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(train_dtm, y_train)\n",
    "\n",
    "# make predictions on test data using test_dtm\n",
    "y_pred = nb.predict(test_dtm)\n",
    "y_pred\n",
    "\n",
    "# compare predictions to true labels\n",
    "print metrics.accuracy_score(y_test, y_pred)\n",
    "#print metrics.confusion_matrix(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
